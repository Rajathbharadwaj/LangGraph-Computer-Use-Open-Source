# LangGraph Computer Use Open Source ğŸ¤–ğŸ’»

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Docker](https://img.shields.io/badge/Docker-Ready-blue.svg)](https://www.docker.com/)
[![LangChain](https://img.shields.io/badge/LangChain-Compatible-green.svg)](https://langchain.com/)
[![Python 3.8+](https://img.shields.io/badge/Python-3.8+-blue.svg)](https://www.python.org/)

**Control any computer using natural language through AI vision and multimodal LLMs**

A production-ready, fully open-source system that combines Docker containerization, VNC remote access, and LangChain/LangGraph integration to create autonomous computer-controlling agents with vision capabilities.

> **ğŸ†š Why Choose This Over LangChain's Official CUA?**
> 
> Unlike LangChain's cloud-dependent solution, this is **100% self-hosted, free, and transparent**:
> - âœ… **No API dependencies** - runs completely offline
> - âœ… **Zero cost** - no Scrapybara subscription fees
> - âœ… **Full control** - inspect, modify, and extend everything
> - âœ… **Real VNC monitoring** - watch your agent work in real-time
> - âœ… **True open source** - Apache/MIT license, no vendor lock-in

## ğŸ¯ What is CUA?

Computer Use Agent (CUA) is an AI system that can:

- **See** - Take screenshots and understand visual content using multimodal LLMs
- **Think** - Process natural language instructions and plan actions
- **Act** - Control mouse, keyboard, and applications with pixel-perfect precision
- **Interact** - Work with any GUI application through visual feedback

Perfect for browser automation, application testing, data entry, and any task requiring computer interaction.

## âœ¨ Key Features

### ğŸ–¥ï¸ **Complete Computer Control**
- Mouse clicks, movement, and scrolling
- Keyboard input and key combinations
- Screenshot capture and analysis
- Window and application management

### ğŸ” **Vision-Powered Intelligence** 
- Anthropic Claude vision integration
- OpenAI GPT-4V support
- Screen understanding and UI element detection
- Natural language descriptions of visual content

### ğŸš€ **Production Ready**
- Dockerized environment with Ubuntu + XFCE
- VNC server for real-time monitoring
- FastAPI server with REST endpoints
- Error handling and retry logic

### ğŸ”§ **LangChain Integration**
- Full LangChain tools compatibility
- LangGraph agent workflows
- Memory and state management
- Streaming responses and checkpoints

### ğŸ›¡ï¸ **Isolation & Safety**
- Sandboxed Docker environment
- VNC monitoring of all actions
- Controlled network access
- Easy start/stop/reset

## ğŸš€ Quick Start

### Prerequisites
- Docker installed
- Python 3.8+
- VNC viewer (optional, for monitoring)

### 1. Clone and Setup

```bash
git clone https://github.com/yourusername/computer-use-agent.git
cd computer-use-agent

# Copy environment template
cp env_example .env
# Edit .env with your API keys
```

### 2. Build and Run Docker Container

```bash
# Build the CUA environment
docker build -f Dockerfile.clean -t cua-agent .

# Run with VNC and API access
docker run -d --name cua-container \
  -p 5900:5900 \
  -p 8001:8001 \
  cua-agent
```

### 3. Install Python Dependencies

```bash
pip install -r requirements_langchain.txt
```

### 4. Set API Keys

Edit `.env` file:
```bash
ANTHROPIC_API_KEY=your-anthropic-key-here
OPENAI_API_KEY=your-openai-key-here  # Optional
```

### 5. Run the Agent

```bash
python langgraph_cua_agent.py
```

Choose option 2 for interactive mode and try:
```
"Navigate to google.com and search for 'AI automation'"
```

## ğŸ® Usage Examples

### Basic Computer Control
```python
from langchain_cua_tools import *

# Take a screenshot
screenshot = await take_screenshot.ainvoke({})

# Click at coordinates
await click_at_coordinates.ainvoke({"x": 100, "y": 200})

# Type text
await type_text.ainvoke({"text": "Hello, AI!"})

# Press key combinations
await press_keys.ainvoke({"keys": ["ctrl", "c"]})
```

### Natural Language Tasks
```python
from langgraph_cua_agent import run_cua_agent_task

# Web browsing
await run_cua_agent_task("Go to GitHub and search for 'langchain'")

# Application automation
await run_cua_agent_task("Open calculator and compute 123 * 456")

# Data entry
await run_cua_agent_task("Fill out the form with test data")

# Visual analysis
await run_cua_agent_task("Describe everything you see on the screen")
```

### Advanced Workflows
```python
# Multi-step automation
task = """
1. Navigate to news.ycombinator.com
2. Find the top story
3. Take a screenshot
4. Summarize the headline and comments
"""
await run_cua_agent_task(task)
```

## ğŸ—ï¸ Architecture

```mermaid
graph TB
    A[Natural Language Input] --> B[LangGraph Agent]
    B --> C[LangChain CUA Tools]
    C --> D[FastAPI Server]
    D --> E[Docker Container]
    E --> F[Ubuntu + XFCE Desktop]
    F --> G[Firefox Browser]
    E --> H[VNC Server]
    H --> I[VNC Viewer - Monitoring]
    
    J[Anthropic Claude] --> B
    K[OpenAI GPT-4V] --> B
    
    style A fill:#e1f5fe
    style B fill:#f3e5f5
    style E fill:#e8f5e8
    style I fill:#fff3e0
```

## ğŸ“ Project Structure

```
computer-use-agent/
â”œâ”€â”€ ğŸ³ Docker Setup
â”‚   â”œâ”€â”€ Dockerfile.clean          # Clean Ubuntu + XFCE environment
â”‚   â”œâ”€â”€ start.sh                  # Container startup script
â”‚   â”œâ”€â”€ cua_server.py            # FastAPI server for computer control
â”‚   â””â”€â”€ .dockerignore            # Docker build optimization
â”‚
â”œâ”€â”€ ğŸ¤– LangChain Integration  
â”‚   â”œâ”€â”€ langgraph_cua_agent.py   # Main agent with LangGraph
â”‚   â”œâ”€â”€ langchain_cua_tools.py   # CUA tools for LangChain
â”‚   â”œâ”€â”€ final_anthropic_cua_tool.py # Anthropic vision integration
â”‚   â””â”€â”€ requirements_langchain.txt  # Python dependencies
â”‚
â”œâ”€â”€ ğŸ“š Documentation
â”‚   â”œâ”€â”€ README.md                # This file
â”‚   â”œâ”€â”€ PRODUCTION_README.md     # Production deployment guide
â”‚   â”œâ”€â”€ README_LANGCHAIN.md      # LangChain integration details
â”‚   â””â”€â”€ env_example             # Environment variables template
â”‚
â””â”€â”€ ğŸ”§ Configuration
    â””â”€â”€ .env                     # API keys (create from env_example)
```

## ğŸ› ï¸ Available Tools

| Tool | Description | Use Case |
|------|-------------|----------|
| `take_screenshot` | Capture current screen | Visual analysis, debugging |
| `click_at_coordinates` | Click at specific location | Button clicks, link navigation |
| `type_text` | Type text at cursor | Form filling, text input |
| `press_keys` | Send key combinations | Shortcuts, navigation |
| `navigate_to_url` | Navigate browser to URL | Web automation |
| `move_cursor` | Move mouse cursor | Hover effects, positioning |
| `scroll_at_location` | Scroll at specific area | Page navigation |
| `double_click_at_coordinates` | Double-click action | File opening, selection |
| `get_screen_dimensions` | Get screen resolution | Layout calculations |
| `take_screenshot_and_analyze` | Screenshot + AI analysis | Vision-powered understanding |

## ğŸ” Monitoring & Debugging

### VNC Access
Connect to `localhost:5900` with any VNC viewer to watch the agent in real-time:

```bash
# Using built-in VNC viewer (macOS)
open vnc://localhost:5900

# Using VNC viewer applications
vncviewer localhost:5900
```

### API Endpoints
The FastAPI server exposes these endpoints:
- `GET /screenshot` - Capture screen
- `POST /click` - Click at coordinates  
- `POST /type` - Type text
- `POST /keypress` - Press keys
- `GET /dimensions` - Get screen size

### Logs and Debugging
```bash
# View container logs
docker logs cua-container

# Execute commands inside container
docker exec -it cua-container bash

# Check API server status
curl http://localhost:8001/dimensions
```

## ğŸ¥Š LangChain Official vs. This Open Source Implementation

| Feature | LangChain Official CUA | **This Open Source CUA** |
|---------|----------------------|---------------------------|
| **Cost** | ğŸ’° Requires Scrapybara API (~$0.10-$1.00/hour) | âœ… **100% Free** |
| **Infrastructure** | â˜ï¸ Cloud-dependent (Scrapybara) | ğŸ  **Self-hosted Docker** |
| **Privacy** | âš ï¸ Data sent to third-party service | ğŸ”’ **Complete data privacy** |
| **Monitoring** | ğŸ“¹ Stream URL (limited) | ğŸ‘ï¸ **Full VNC access** |
| **Customization** | ğŸ”’ Limited to API parameters | ğŸ› ï¸ **Full source code control** |
| **Offline Capability** | âŒ Requires internet | âœ… **Works completely offline** |
| **Setup Complexity** | ğŸ”‘ API keys + billing setup | ğŸ³ **Just Docker run** |
| **Vendor Lock-in** | ğŸ”— Tied to Scrapybara service | ğŸ†“ **Vendor independent** |
| **Environment Control** | ğŸ¢ Predefined Ubuntu/Windows VMs | ğŸ¨ **Custom Docker environments** |
| **Data Retention** | âš ï¸ Subject to vendor policies | ğŸ—‘ï¸ **You control all data** |
| **Debugging** | ğŸ“Š Limited API logs | ğŸ” **Full container access** |
| **Extensions** | ğŸ“¦ Limited to LangChain ecosystem | ğŸ”§ **Extend anything** |

### ğŸ¯ **Why This Matters**

#### **ğŸ’° Cost Savings**
```bash
# LangChain Official: $0.10-$1.00 per hour
# 8 hours/day Ã— 30 days = $24-$240/month per agent

# This implementation: $0
# Run unlimited agents forever
```

#### **ğŸ”’ Complete Privacy**
```python
# LangChain Official: Screenshots sent to Scrapybara
screenshot_data â†’ Scrapybara API â†’ Their servers

# This implementation: Everything local
screenshot_data â†’ Local Docker â†’ Your control
```

#### **ğŸ› ï¸ Full Customization**
```python
# LangChain Official: Limited parameters
cua_graph = create_cua(
    timeout_hours=2,  # Only basic config
    environment="ubuntu"
)

# This implementation: Modify everything
class CustomCUAServer(FastAPI):
    def custom_screenshot_processing(self):
        # Your custom logic here
        pass
```

#### **ğŸ‘ï¸ Real-Time Monitoring**
```bash
# LangChain Official: Stream URL (view only)
# Limited visibility into what's happening

# This implementation: Full VNC access
vncviewer localhost:5900
# Watch, interact, debug in real-time
```

## ğŸ¨ Advanced Features

### Custom LLM Providers

```python
# Use Anthropic Claude
from langchain_anthropic import ChatAnthropic
llm = ChatAnthropic(model="claude-3-sonnet-20240229")

# Use local models via Ollama
from langchain_ollama import ChatOllama
llm = ChatOllama(model="llama3")
```

### Memory and Persistence

```python
from langgraph.checkpoint.sqlite import SqliteSaver
memory = SqliteSaver.from_conn_string("checkpoints.sqlite")
agent = create_react_agent(llm, tools, checkpointer=memory)
```

### Tool Composition

```python
# Combine with other LangChain tools
from langchain_community.tools import DuckDuckGoSearchRun, WikipediaQueryRun

tools = get_all_cua_tools() + [
    DuckDuckGoSearchRun(),
    WikipediaQueryRun()
]
```

## ğŸ›¡ï¸ Safety & Security

### Isolation
- **Docker sandbox** prevents system access
- **Network isolation** controls internet access
- **VNC monitoring** shows all agent actions
- **Resource limits** prevent system overload

### Best Practices
- Always monitor via VNC during development
- Use rate limiting for production deployments
- Implement approval workflows for sensitive actions
- Regular container restarts for clean state

### Error Handling
- Automatic retries on network failures
- Vision-based error detection and recovery
- Graceful degradation when tools fail
- Comprehensive logging for debugging

## ğŸš€ Production Deployment

### Scaling
```bash
# Run multiple containers
docker run -d --name cua-1 -p 5901:5900 -p 8002:8001 cua-agent
docker run -d --name cua-2 -p 5902:5900 -p 8003:8001 cua-agent
```

### Resource Management
```bash
# Set resource limits
docker run -d --name cua-container \
  --memory="2g" \
  --cpus="1.0" \
  -p 5900:5900 -p 8001:8001 \
  cua-agent
```

### Health Monitoring
```python
# Health check endpoint
@app.get("/health")
async def health_check():
    return {"status": "healthy", "timestamp": time.time()}
```

## ğŸ¤ Contributing

We welcome contributions! Here's how to get started:

1. **Fork the repository**
2. **Create a feature branch**: `git checkout -b feature/amazing-feature`
3. **Make your changes**:
   - Add new tools in `langchain_cua_tools.py`
   - Enhance agent behavior in `langgraph_cua_agent.py`
   - Improve Docker setup in `Dockerfile.clean`
   - Update documentation
4. **Test thoroughly** with VNC monitoring
5. **Submit a pull request**

### Development Setup
```bash
# Clone your fork
git clone https://github.com/yourusername/computer-use-agent.git
cd computer-use-agent

# Install development dependencies
pip install -r requirements_langchain.txt
pip install pytest black flake8

# Run tests
pytest

# Format code
black .
```

## ğŸ› Troubleshooting

### Common Issues

**Container won't start**
```bash
# Check Docker logs
docker logs cua-container

# Common fix: remove old containers
docker rm -f cua-container
```

**VNC connection fails**
```bash
# Verify port is exposed
docker port cua-container 5900

# Check if VNC is running inside container
docker exec cua-container ps aux | grep vnc
```

**API not responding**
```bash
# Test API directly
curl http://localhost:8001/dimensions

# Check FastAPI server logs
docker exec cua-container cat /app/server.log
```

**Agent actions not working**
- Verify container is running: `docker ps`
- Check VNC to see actual screen state
- Ensure API keys are set correctly
- Monitor logs for error messages

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- **Anthropic** for Claude vision capabilities
- **OpenAI** for GPT-4 vision API
- **LangChain** for the agent framework
- **Docker** for containerization
- **XFCE** for the lightweight desktop environment

## ğŸ“¬ Support

- **Issues**: [GitHub Issues](https://github.com/yourusername/computer-use-agent/issues)
- **Discussions**: [GitHub Discussions](https://github.com/yourusername/computer-use-agent/discussions)
- **Documentation**: Check the `docs/` folder for detailed guides

---

**â­ Star this repo if you find it useful!**

**ğŸš€ Ready to automate your computer with AI? Get started now!**
